{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e396913-be41-4d5a-ac52-718b013e081a",
   "metadata": {
    "id": "1e396913-be41-4d5a-ac52-718b013e081a"
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kzIfd4FYBTYX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzIfd4FYBTYX",
    "outputId": "c3c6e286-7f58-47c4-d911-128e5226dbf1"
   },
   "outputs": [],
   "source": [
    "# mount cuda if available else cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ba84f-3b2f-4b0d-b0d9-59b668de921e",
   "metadata": {
    "id": "137ba84f-3b2f-4b0d-b0d9-59b668de921e"
   },
   "outputs": [],
   "source": [
    "with open('../data/telegram_df', 'rb') as file:\n",
    "    telegram_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efa097-c62a-4a06-81ad-adb786100a78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "e0efa097-c62a-4a06-81ad-adb786100a78",
    "outputId": "44d56849-a700-4026-f211-b3c465f74d66"
   },
   "outputs": [],
   "source": [
    "# new columns to reflect actions (1 is recommend 0 is dont recommend)\n",
    "telegram_df.columns = ['text', 1]\n",
    "telegram_df[0] = telegram_df[1].apply(lambda score:-10 if score < 0 else 10)\n",
    "telegram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e84f46-f869-47ce-bdfd-1bb527d051b0",
   "metadata": {
    "id": "65e84f46-f869-47ce-bdfd-1bb527d051b0"
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sbert_embeddings.pkl\", \"rb\") as f:\n",
    "    telegram_embs = pickle.load(f)\n",
    "telegram_tensors = [torch.tensor(emb) for emb in telegram_embs]\n",
    "telegram_tensors = torch.vstack(telegram_tensors)\n",
    "telegram_tensors = telegram_tensors.to(device)\n",
    "tensor_dims = telegram_tensors.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9733f3-6f5f-4b6a-a3ad-e1387a5ce212",
   "metadata": {
    "id": "ce9733f3-6f5f-4b6a-a3ad-e1387a5ce212"
   },
   "outputs": [],
   "source": [
    "X = [idx for idx in range(len(telegram_tensors))]\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "X_val, X_test = train_test_split(X_test, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558ec69-e1a4-487c-a851-14daae59e321",
   "metadata": {
    "id": "0558ec69-e1a4-487c-a851-14daae59e321"
   },
   "outputs": [],
   "source": [
    "# formula for ndcg\n",
    "def ndcg(relevance_scores, k):\n",
    "    relevance_scores = [score if score >=0 else 0 for score in relevance_scores]\n",
    "    if len(relevance_scores) == 0:\n",
    "        return 0\n",
    "    k = min(k, len(relevance_scores))\n",
    "    dcg = np.sum(relevance_scores[:k] / np.log2(np.arange(2, k + 2)))\n",
    "    ideal_relevance_scores = sorted(relevance_scores, reverse = True)\n",
    "    idcg = np.sum(ideal_relevance_scores[:k] / np.log2(np.arange(2, k + 2)))\n",
    "    if idcg ==0:\n",
    "        return 0\n",
    "    ndcg = dcg / idcg\n",
    "    if ndcg > 1:\n",
    "        print('NDCG ERROR')\n",
    "        print('relevance scores:', relevance_scores)\n",
    "        print('dcg:', dcg)\n",
    "        print('idcg:', idcg)\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f046211-3bb8-45f8-b488-5792780d8767",
   "metadata": {
    "id": "9f046211-3bb8-45f8-b488-5792780d8767"
   },
   "outputs": [],
   "source": [
    "# make class for bandit model\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_prob=0.3):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.lin_1 = nn.Linear(input_dim, input_dim // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.lin_2 = nn.Linear(input_dim // 2, 2)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.lin_1(state)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin_2(x)\n",
    "        return x\n",
    "\n",
    "class RankingAgent:\n",
    "    def __init__(self, input_dim, learning_rate=0.001, epsilon=1, pretrained_model=None):\n",
    "        self.input_dim = input_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon = epsilon\n",
    "        self.model = QNetwork(input_dim).to(device)\n",
    "        if pretrained_model:\n",
    "            self.model.load_state_dict(pretrained_model)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "\n",
    "\n",
    "    def choose_action(self, current_state):\n",
    "        current_state = current_state.to(device)\n",
    "        q_scores = self.model(current_state)\n",
    "        if torch.rand(1).item() > self.epsilon:\n",
    "            action = torch.argmax(q_scores).item()\n",
    "        else:\n",
    "            action = random.choice([0, 1])\n",
    "        self.epsilon = max(self.epsilon * self.epsilon_decay, self.epsilon_min)\n",
    "        return action\n",
    "\n",
    "    def eval(self, selected_post_embs, indices):\n",
    "        selected_post_embs = selected_post_embs.to(device)\n",
    "        with torch.no_grad():\n",
    "          q_scores = self.model(selected_post_embs)\n",
    "          actions = torch.argmax(q_scores, dim=1).cpu().numpy()\n",
    "          highest_q_scores = torch.max(q_scores, dim=1).values.cpu().numpy()\n",
    "        sorted_posts = sorted(zip(indices, highest_q_scores, actions), key=lambda x: x[1], reverse=True)\n",
    "        selected_posts = [post[0] for post in sorted_posts if post[2] == 1]\n",
    "        return selected_posts\n",
    "\n",
    "    def update(self, current_state, action, reward):\n",
    "        current_state = current_state.to(device)\n",
    "        q_value = torch.max(self.model(current_state))\n",
    "        target_q_value = torch.tensor(reward, dtype=torch.float32).to(device)\n",
    "        loss = self.loss_fn(q_value, target_q_value)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qraQ8IcRRpaG",
   "metadata": {
    "id": "qraQ8IcRRpaG"
   },
   "outputs": [],
   "source": [
    "# generate random data to use as baseline comparision\n",
    "NUM_STEPS = 1000\n",
    "SAMPLE_SIZE = 50\n",
    "random_rewards = []\n",
    "random_ndcgs = []\n",
    "random_preds = []\n",
    "random_true = []\n",
    "random_cumulative_reward = 0\n",
    "for _ in range(NUM_STEPS):\n",
    "    random_idx = random.choice(X_val)\n",
    "    random_action = random.choice([0, 1])\n",
    "    random_preds.append(random_action)\n",
    "    random_true.append(1 if telegram_df[random_action][random_idx] > 0 else 0)\n",
    "    reward = telegram_df[random_action][random_idx]\n",
    "    random_cumulative_reward += reward\n",
    "    random_rewards.append(random_cumulative_reward)\n",
    "\n",
    "for _ in range(NUM_STEPS):\n",
    "    random_posts = random.sample(X, 10)\n",
    "    random_ndcg = ndcg(telegram_df[1][random_posts], 10)\n",
    "    random_ndcgs.append(random_ndcg)\n",
    "\n",
    "random_data = (random_rewards, random_ndcgs)\n",
    "#optionally save random data\n",
    "#with open('../data/random_bandit_data.pkl', 'wb') as file:\n",
    " #   pickle.dump(random_data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc4bfe-7cad-422e-97b1-d1ae9c6b4bf9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ebc4bfe-7cad-422e-97b1-d1ae9c6b4bf9",
    "outputId": "bdc29865-410a-4713-df7d-5268880fb94e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train bandit model\n",
    "TOP_N_POSTS = 10\n",
    "NUM_STEPS = 1000\n",
    "SAMPLE_SIZE = 50\n",
    "best_model = None\n",
    "best_val_ndcg = 0\n",
    "learning_rates = [0.001, 0.01, 0.02, 0.05, 0.1]\n",
    "epsilons = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "model_training_data = {}\n",
    "for learning_rate in learning_rates:\n",
    "    for epsilon in epsilons:\n",
    "        agent_best_recommend = np.inf\n",
    "        agent_best_not_recommend = np.inf\n",
    "        preds_train = []\n",
    "        true_train = []\n",
    "        preds_val = []\n",
    "        true_val = []\n",
    "        train_ndcgs = []\n",
    "        val_ndcgs = []\n",
    "        train_rewards = []\n",
    "        val_rewards = []\n",
    "\n",
    "        train_reward_cumulative = 0\n",
    "        val_reward_cumulative = 0\n",
    "        best_train_ndcg = 0\n",
    "        best_agent_model = None\n",
    "        agent = RankingAgent(input_dim=telegram_tensors.size(1), learning_rate = learning_rate, epsilon = epsilon)\n",
    "        best_train_model = None\n",
    "        bad_counter = 0\n",
    "        for i in tqdm(range(NUM_STEPS)):\n",
    "            random_idx = random.choice(X_train)\n",
    "            state = telegram_tensors[random_idx]\n",
    "            action = agent.choose_action(state)\n",
    "            preds_train.append(action)\n",
    "            reward = telegram_df[action][random_idx]\n",
    "            true_train.append(1 if reward >0 else 0)\n",
    "            train_reward_cumulative += reward\n",
    "            agent.update(state, action, reward)\n",
    "            train_rewards.append(train_reward_cumulative)\n",
    "\n",
    "            random_idx = random.choice(X_val)\n",
    "            state = telegram_tensors[random_idx]\n",
    "            action = agent.choose_action(state)\n",
    "            preds_val.append(action)\n",
    "            true_val.append(1 if reward >0 else 0)\n",
    "            reward = telegram_df[action][random_idx]\n",
    "            val_reward_cumulative += reward\n",
    "            val_rewards.append(val_reward_cumulative)\n",
    "\n",
    "            random_train = random.sample(X_train, SAMPLE_SIZE)\n",
    "            ordered_posts = agent.eval(telegram_tensors[random_train], X_train)\n",
    "            rewards = telegram_df[1][ordered_posts]\n",
    "            train_ndcg = ndcg(rewards,TOP_N_POSTS)\n",
    "            train_ndcgs.append(train_ndcg)\n",
    "\n",
    "            random_val = random.sample(X_val, SAMPLE_SIZE)\n",
    "            ordered_posts = agent.eval(telegram_tensors[random_val], X_val)\n",
    "            rewards = telegram_df[1][ordered_posts]\n",
    "            val_ndcg = ndcg(rewards,TOP_N_POSTS)\n",
    "            val_ndcgs.append(val_ndcg)\n",
    "\n",
    "            if agent.epsilon < 0.01:\n",
    "                if np.mean(train_ndcgs[i-10:i]) > best_train_ndcg:\n",
    "                    best_train_ndcg = train_ndcg\n",
    "                    best_train_model = agent.model.state_dict()\n",
    "                    bad_counter = 0\n",
    "                else:\n",
    "                    bad_counter += 1\n",
    "                    if bad_counter == 10:\n",
    "                        agent.model.load_state_dict(best_agent_model)\n",
    "                        agent.epsilon = 0.2\n",
    "                        bad_counter = 0\n",
    "                if np.mean(val_ndcg[i-10:i]) > best_val_ndcg:\n",
    "                    best_val_ndcg = val_ndcg\n",
    "                    best_model = agent.model.state_dict()\n",
    "        key = str(epsilon) + '_' + str(learning_rate)\n",
    "        model_training_data[key] = (train_ndcgs, val_ndcgs,  train_rewards, val_rewards, preds_train, true_train, preds_val, true_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voe9IfU1RNxy",
   "metadata": {
    "id": "voe9IfU1RNxy"
   },
   "outputs": [],
   "source": [
    "# optionally save data\n",
    "#with open('../data/bandit_model_data.pkl', 'wb') as file:\n",
    "  #  pickle.dump(model_training_data, file)\n",
    "#with open('../data/bandit_best_model', 'wb') as f:\n",
    " #       pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dSt0KZqu7mqp",
   "metadata": {
    "id": "dSt0KZqu7mqp"
   },
   "outputs": [],
   "source": [
    "# load data if kernel timeout\n",
    "#with open('../data/bandit_model_data.pkl', 'rb') as file:\n",
    " #   model_training_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RnqVsJUkLyjq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "RnqVsJUkLyjq",
    "outputId": "734fe348-7157-41c0-8fb7-d0557f6ded9a"
   },
   "outputs": [],
   "source": [
    "# generate visualizations\n",
    "data = model_training_data\n",
    "learning_rates = [0.001, 0.01, 0.02, 0.05, 0.1]\n",
    "epsilons = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "random_rewards = random_data[0]\n",
    "random_ndcgs = random_data[1]\n",
    "\n",
    "num_rows = 3\n",
    "num_cols = 2\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10*num_cols, 12))\n",
    "axes = axes.flatten()\n",
    "for idx, epsilon in enumerate(epsilons):\n",
    "\n",
    "    for learning_rate in learning_rates:\n",
    "        val_reward = np.array([data[str(epsilon) + '_' + str(learning_rate)][3] for learning_rate in learning_rates])\n",
    "        val_df = pd.DataFrame(data=val_reward.T, columns=learning_rates)\n",
    "        sns.lineplot(data=val_df[learning_rate], ax=axes[idx],  dashes=False, label=f\"Learning Rate {learning_rate}\")\n",
    "    val_df['Random'] = random_rewards\n",
    "    sns.lineplot(data=val_df['Random'], ax=axes[idx], dashes=False, label=f\"Random Recommendation\")\n",
    "\n",
    "    axes[idx].set_title(f\"Validation Cumulative Rewards at Epsilon = {epsilon}\")\n",
    "    axes[idx].set_xlabel(\"Step\")\n",
    "    axes[idx].set_ylabel(\"Cumulative Reward\")\n",
    "    axes[idx].legend(title=\"Learning Rates\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QoRMqGJOL4lZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QoRMqGJOL4lZ",
    "outputId": "e50868f6-297d-4e4e-fd67-573c3e728d04"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(6*num_cols, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, epsilon in enumerate(epsilons):\n",
    "    train_ndcgs = np.array([data[str(epsilon) + '_' + str(learning_rate)][0] for learning_rate in learning_rates])\n",
    "    ndcg_df = pd.DataFrame(data=train_ndcgs.T, columns=learning_rates)\n",
    "\n",
    "    for learning_rate in learning_rates:\n",
    "        sns.kdeplot(ndcg_df[learning_rate],  label=f\"Learning Rate {learning_rate}\", ax=axes[idx])\n",
    "    sns.kdeplot(random_ndcgs, label=f\"Random Strategy\", ax=axes[idx])\n",
    "\n",
    "    axes[idx].set_title(f\"Distribution of NDCGs at Epsilon = {epsilon}\")\n",
    "    axes[idx].set_xlabel(\"NDCG Value\")\n",
    "    axes[idx].set_ylabel(\"Density\")\n",
    "    axes[idx].legend(title=\"Learning Rates\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('train_ndcgs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jjuxJ_-tL7fM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "jjuxJ_-tL7fM",
    "outputId": "f70db698-6995-47f8-e336-46e812fde952"
   },
   "outputs": [],
   "source": [
    "preds_train = data[str(0) + '_' + str(0.01)][4]\n",
    "true_train = data[str(0) + '_' + str(0.01)][5]\n",
    "cm = confusion_matrix(true_train, preds_train)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(true_train))\n",
    "disp.plot(cmap='Blues')\n",
    "\n",
    "plt.title(\"Epsilon = 0, Learning Rate = 0.01\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8vh5LT77RGH-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "8vh5LT77RGH-",
    "outputId": "07c9d2bf-b64f-4b6f-f6f4-bcfc6c15eb3f"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(random_true, random_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(true_train))\n",
    "disp.plot(cmap='Blues')\n",
    "\n",
    "plt.title(\"Random Strategy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NWysxkvNSOLf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWysxkvNSOLf",
    "outputId": "e1e5cd52-3b45-45d7-9ade-14f0068ad346"
   },
   "outputs": [],
   "source": [
    "print('Model Average NDCG:', np.mean(data[str(0) + '_' + str(0.01)][1]))\n",
    "print('Random Strategy Average NDCG:', np.mean(random_ndcgs))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
