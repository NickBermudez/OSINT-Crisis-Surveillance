{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee124b8-e84d-4ef9-842f-33e91508d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import spacy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import wordnet\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c719888c-faed-4e66-9bd2-51fc8c0c41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NLP processing tools\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811dc06-c4a0-46e9-9a2e-12fbcef42bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scraped data\n",
    "with open(r'../data/bellumactanews1.json', 'r', encoding='utf-8') as f:\n",
    "    belumactanews = json.load(f)\n",
    "with open(r'../data/IntelSlavaZ.json', 'r', encoding='utf-8') as f:\n",
    "    intelslava = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914167d-35b4-4bff-8e67-2303e448169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from message\n",
    "def extract_text(message):\n",
    "    text = message.get('text', '')\n",
    "    # Handle cases where text is a list of dicts (which can happen in Telegram exports)\n",
    "    if isinstance(text, list):\n",
    "        text_parts = []\n",
    "        for part in text:\n",
    "            if isinstance(part, str):\n",
    "                text_parts.append(part)\n",
    "            elif isinstance(part, dict) and 'text' in part:\n",
    "                text_parts.append(part['text'])\n",
    "        text = ' '.join(text_parts)\n",
    "    elif not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967865ba-43cc-4177-952b-eb459a994417",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_intelslava = intelslava.get('messages', [])\n",
    "texts = []\n",
    "for msg in messages_intelslava:\n",
    "    if msg.get('type') == 'message':\n",
    "        text = extract_text(msg)\n",
    "        if text.strip():\n",
    "            texts.append(text)\n",
    "messages_belumacta = intelslava.get('messages', [])\n",
    "for msg in messages_belumacta:\n",
    "    if msg.get('type') == 'message':\n",
    "        text = extract_text(msg)\n",
    "        if text.strip():\n",
    "            texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a12ef-57c3-42ca-92f1-3ccf3c820a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_df = pd.DataFrame(texts, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864cafb-1e40-4f20-a4d3-d05e54529ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df = pd.read_csv('../data/russia_ukraine_public.csv')\n",
    "public_df = pd.DataFrame(data = public_df['text'], columns = ['text'])\n",
    "telegram_df = pd.concat([public_df, scraped_df])\n",
    "telegram_df = telegram_df.dropna()\n",
    "telegram_df['text'] = telegram_df['text'].apply(lambda text: text.replace('\\n', ' '))\n",
    "telegram_df.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c71a9bc-166b-4701-b1a5-a800d2b4df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(keywords):\n",
    "    synonyms = {}\n",
    "    for word in keywords:\n",
    "        related_words = set()\n",
    "        for synset in wordnet.synsets(word):\n",
    "            for lemma in synset.lemmas():\n",
    "                related_words.add(lemma.name())\n",
    "        synonyms[word] = list(related_words)\n",
    "    all_synonyms = []\n",
    "    for word, related_words in synonyms.items():\n",
    "        related_words = [word.replace('_', ' ') for word in related_words]\n",
    "        all_synonyms = all_synonyms + related_words\n",
    "    \n",
    "    return all_synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65114c17-3747-4d56-b757-fd41c60b2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel:\n",
    "    def __init__(self, min_length, name_weight, sentiment_weight, keywords, eval_mode = True):\n",
    "        self.min_length = min_length  \n",
    "        self.name_weight = name_weight  \n",
    "        self.sentiment_weight = sentiment_weight\n",
    "        self.keywords = keywords\n",
    "        self.eval_mode = eval_mode\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        doc = nlp(text)\n",
    "        return [token.text.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "    def count_keyword_matches(self, text, threshold=80):\n",
    "        vanilla_text = text.lower().split()\n",
    "        processed_text = set(self.preprocess_text(text))  \n",
    "        match_count = 0\n",
    "        for keyword in self.keywords:\n",
    "            for word in processed_text:\n",
    "                similarity = fuzz.ratio(keyword.lower(), word)  \n",
    "                if similarity >= threshold:  \n",
    "                    match_count += 1\n",
    "                    break\n",
    "                else:\n",
    "                    if keyword in vanilla_text:\n",
    "                        match_count += 1\n",
    "                        break\n",
    "        \n",
    "        return match_count\n",
    "\n",
    "    def extract_named_entities(self, text):\n",
    "        doc = nlp(text)\n",
    "        names = [ent.text for ent in doc.ents if ent.label_ in [\"ORG\", \"GPE\"]]\n",
    "        return names\n",
    "\n",
    "    def sentiment_analysis(self, text):\n",
    "        sentiment = sia.polarity_scores(text)\n",
    "        return sentiment[\"compound\"]\n",
    "\n",
    "    def check_for_links(self, text):\n",
    "        return \"http\" in text or \"https\" in text\n",
    "\n",
    "    def score_post(self, post):\n",
    "        post_length = len(post.split())\n",
    "        length_score = -5 if post_length <= self.min_length else 0\n",
    "        keyword_matches = self.count_keyword_matches(post)\n",
    "        keyword_score = 2 * keyword_matches if keyword_matches > 0 else - 10\n",
    "        person_names = self.extract_named_entities(post)\n",
    "        name_score = len(person_names) * self.name_weight\n",
    "        sentiment_score = self.sentiment_analysis(post) * self.sentiment_weight\n",
    "        link_score = 5 if (self.check_for_links(post) and keyword_score > 0) else 0\n",
    "        total_score = (\n",
    "            length_score +\n",
    "            keyword_score +\n",
    "            name_score +\n",
    "            sentiment_score +\n",
    "            link_score \n",
    "        )\n",
    "        if self.eval_mode:\n",
    "            print('length_score:',length_score, 'keyword_score:',keyword_score, 'name_score:',name_score, 'sentiment_score:',sentiment_score)\n",
    "            print('link_score:',link_score)\n",
    "        return total_score\n",
    "\n",
    "keywords = ['russia', 'ukraine', 'ukranian', 'russian', 'ukranians', 'russians', 'üá∑üá∫', 'üá∑üá∫üá∫üá¶', '‚ö°Ô∏è', 'war', 'üá∫üá¶', 'putin', 'Putin', 'Zelenskyy'] \n",
    "synonyms = get_synonyms(keywords)\n",
    "keywords = keywords + synonyms\n",
    "user_model = UserModel(min_length=5, name_weight=1, sentiment_weight=-3, keywords=keywords)\n",
    "\n",
    "\n",
    "posts = telegram_df.sample(n=10)['text']\n",
    "for post in posts:\n",
    "    print(post)\n",
    "    score = user_model.score_post(post)\n",
    "    print(f\"Post relevance score: {score}\")\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeac6d9-4516-489c-8546-84f340b8506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "user_model = UserModel(min_length=5, name_weight=1, sentiment_weight=-3, keywords=keywords, eval_mode=False)\n",
    "telegram_df['reward'] = telegram_df['text'].progress_apply(lambda text: user_model.score_post(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad4eab-4ffc-45db-877e-abfbd6dbc5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/telegram_df', 'wb') as file:\n",
    "    pickle.dump(telegram_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d62dd5-d474-444c-97fe-faacb434a768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
