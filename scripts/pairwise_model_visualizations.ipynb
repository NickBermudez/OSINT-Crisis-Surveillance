{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e396913-be41-4d5a-ac52-718b013e081a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1e396913-be41-4d5a-ac52-718b013e081a",
    "outputId": "83644349-fb16-4a5c-ba76-03760aa78fab"
   },
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pairwise_model\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kzIfd4FYBTYX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzIfd4FYBTYX",
    "outputId": "3c97d2e7-6e14-4b0c-8c01-f076e2713ef9"
   },
   "outputs": [],
   "source": [
    "# set device to cuda if avaiable, else cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ba84f-3b2f-4b0d-b0d9-59b668de921e",
   "metadata": {
    "id": "137ba84f-3b2f-4b0d-b0d9-59b668de921e"
   },
   "outputs": [],
   "source": [
    "# load the post and reward dataframe\n",
    "with open(\"../data/telegram_df.pkl\", 'rb') as file:\n",
    "    telegram_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efa097-c62a-4a06-81ad-adb786100a78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "e0efa097-c62a-4a06-81ad-adb786100a78",
    "outputId": "b5463b31-69bd-4fc1-ff6e-cbf85cb38aea"
   },
   "outputs": [],
   "source": [
    "telegram_df.columns = ['text', 'reward']\n",
    "telegram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e84f46-f869-47ce-bdfd-1bb527d051b0",
   "metadata": {
    "id": "65e84f46-f869-47ce-bdfd-1bb527d051b0"
   },
   "outputs": [],
   "source": [
    "# load the SBERT embeddings\n",
    "with open(\"../data/sbert_embeddings.pkl\", \"rb\") as f:\n",
    "    telegram_embs = pickle.load(f)\n",
    "telegram_tensors = [torch.tensor(emb) for emb in telegram_embs]\n",
    "# put embeddings into one tensor for easy access\n",
    "telegram_tensors = torch.vstack(telegram_tensors)\n",
    "telegram_tensors = telegram_tensors.to(device)\n",
    "tensor_dims = telegram_tensors.size(1) # number features used for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9733f3-6f5f-4b6a-a3ad-e1387a5ce212",
   "metadata": {
    "id": "ce9733f3-6f5f-4b6a-a3ad-e1387a5ce212"
   },
   "outputs": [],
   "source": [
    "X = [idx for idx in range(len(telegram_tensors))]\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "X_val, X_test = train_test_split(X_test, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558ec69-e1a4-487c-a851-14daae59e321",
   "metadata": {
    "id": "0558ec69-e1a4-487c-a851-14daae59e321"
   },
   "outputs": [],
   "source": [
    "# formula for calculating ndcg\n",
    "def ndcg(relevance_scores, k):\n",
    "    relevance_scores = [score if score >=0 else 0 for score in relevance_scores]\n",
    "    if len(relevance_scores) == 0:\n",
    "        return 0\n",
    "    k = min(k, len(relevance_scores))\n",
    "    dcg = np.sum(relevance_scores[:k] / np.log2(np.arange(2, k + 2)))\n",
    "    ideal_relevance_scores = sorted(relevance_scores, reverse = True)\n",
    "    idcg = np.sum(ideal_relevance_scores[:k] / np.log2(np.arange(2, k + 2)))\n",
    "    if idcg ==0:\n",
    "        return 0\n",
    "    ndcg = dcg / idcg\n",
    "    # error checks\n",
    "    if ndcg > 1:\n",
    "        raise ValueError(\"NDCG cannot be greater than 1\")\n",
    "    if ndcg < 0:\n",
    "        raise ValueError(\"NDCG cannot be less than 0\")\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc4bfe-7cad-422e-97b1-d1ae9c6b4bf9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ebc4bfe-7cad-422e-97b1-d1ae9c6b4bf9",
    "outputId": "6daee8b2-92e3-4a4b-add9-02ee44bdbf1d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# keep track of the best loss and ndcg to determine best model\n",
    "best_model = None\n",
    "best_ndcg = 0\n",
    "best_loss = np.inf\n",
    "train_sizes = [5, 10, 15, 20]\n",
    "learning_rates = [1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "#save data for analysis and visualizations\n",
    "model_training_data = {}\n",
    "\n",
    "# gather hyperparameter data\n",
    "for lr in learning_rates:\n",
    "    for train_size in tqdm(train_sizes):\n",
    "        agent = pairwise_model.RankingAgent(tensor_dims, learning_rate = lr, train_size = train_size)\n",
    "        num_posts_used = 0\n",
    "        posts_used = []\n",
    "        model_ndcgs = []\n",
    "        model_losses = []\n",
    "\n",
    "        while num_posts_used<1000:\n",
    "            train_indices = random.sample(X_train, train_size)\n",
    "            for idx in train_indices:\n",
    "                embedding = telegram_tensors[idx]\n",
    "                relevance_score = telegram_df['reward'][idx]\n",
    "                agent.save_post_ranking(relevance_score, embedding)\n",
    "            agent.train()\n",
    "            iteration_loss = agent.loss/(train_size*(train_size-1)/2)\n",
    "            model_losses.append(iteration_loss)\n",
    "            val_indices = random.sample(X_val, 50)\n",
    "            post_embeddings = telegram_tensors[val_indices]\n",
    "            ranked_indices = agent.rank_posts(post_embeddings)\n",
    "            ranked_post_indices = [val_indices[idx] for idx in ranked_indices]\n",
    "            model_rewards = [telegram_df['reward'][idx] for idx in ranked_post_indices]\n",
    "            model_ndcg = ndcg(model_rewards, 10)\n",
    "            model_ndcgs.append(model_ndcg)\n",
    "            if model_ndcg > best_ndcg and iteration_loss < best_loss:\n",
    "                best_ndcg = model_ndcg\n",
    "                best_loss = iteration_loss\n",
    "                best_model = agent.model.state_dict()\n",
    "            num_posts_used += train_size\n",
    "            posts_used.append(num_posts_used)\n",
    "            agent.loss = 0\n",
    "        print('Training Size:',train_size,'Learning Rate:',lr,'Average NDCG:',np.mean(model_ndcgs),'Best NDCG:',best_ndcg)\n",
    "        model_training_data[str(lr) + '_' + str(train_size)] = (model_ndcgs, model_losses, posts_used)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KgqNIBuZ1dH0",
   "metadata": {
    "id": "KgqNIBuZ1dH0"
   },
   "outputs": [],
   "source": [
    "# optionally save the data\n",
    "#with open('../data/pairwise_model_data.pkl', 'wb') as file:\n",
    " #   pickle.dump(model_training_data, file)\n",
    "#with open('../data/best_pairwise_model', 'wb') as f:\n",
    "#        pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xqrhYFw2L2LN",
   "metadata": {
    "id": "xqrhYFw2L2LN"
   },
   "outputs": [],
   "source": [
    "# open the data if already generated\n",
    "#with open('../data/pairwise_model_data.pkl', 'rb') as file:\n",
    "#    model_training_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1xV73Ts-DknD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "1xV73Ts-DknD",
    "outputId": "99490596-a44e-489e-9ce3-d3223cf8bd67"
   },
   "outputs": [],
   "source": [
    "# generate random data for comparison\n",
    "train_sizes = [5, 10, 15, 20]\n",
    "learning_rates = [1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "random_ndcgs = []\n",
    "random_preds = []\n",
    "random_true = []\n",
    "for _ in range(1000):\n",
    "  random_indices = random.sample(X_val, 50)\n",
    "  random_ranking = random.sample(random_indices, len(random_indices))\n",
    "  random_rewards = [telegram_df['reward'][idx] for idx in random_ranking]\n",
    "  random_ndcgs.append(ndcg(random_rewards, 10))\n",
    "\n",
    "for _ in range(1000):\n",
    "  random_choice = random.choice([0,1])\n",
    "  random_preds.append(random_choice)\n",
    "  random_reward = random.choice(telegram_df['reward'])\n",
    "  random_true.append(1 if random_reward >0 else 0)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# visualize ndcg distributions with kernel density estimation\n",
    "for idx, lr in enumerate(learning_rates):\n",
    "    ax = axes[idx]\n",
    "    sns.kdeplot(random_ndcgs, color='blue', label='Random Strategy', ax=ax)\n",
    "    for train_size in train_sizes:\n",
    "        model_ndcgs = model_training_data[f\"{lr}_{train_size}\"][0]\n",
    "        sns.kdeplot(model_ndcgs, label=f'Training Size: {train_size}', ax=ax)\n",
    "    ax.set_title(f'KDE of NDCG Scores at Learning Rate={lr}', fontsize=14)\n",
    "    ax.set_xlabel('NDCG Score', fontsize=12)\n",
    "    ax.set_ylabel('Density', fontsize=12)\n",
    "    ax.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RnqVsJUkLyjq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "id": "RnqVsJUkLyjq",
    "outputId": "40dc6689-ab0b-4a24-e207-c1e46f03d7d2"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# visualize model losses over time\n",
    "for idx, lr in enumerate(learning_rates):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    for train_size in train_sizes:\n",
    "        model_losses = model_training_data[f\"{lr}_{train_size}\"][1]\n",
    "        num_posts = model_training_data[f\"{lr}_{train_size}\"][2]\n",
    "        ax.plot(num_posts, model_losses, label=f'Train Size {train_size}')\n",
    "\n",
    "    ax.set_title(f'Model Losses by Number of Posts Sampled\\nLearning Rate={lr}', fontsize=14)\n",
    "    ax.set_xlabel('Number of Posts Used', fontsize=12)\n",
    "    ax.set_ylabel('Loss', fontsize=12)\n",
    "    ax.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_losses_by_posts.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QoRMqGJOL4lZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "QoRMqGJOL4lZ",
    "outputId": "2f6895bf-8556-44c8-c2c6-5788403a6d1d"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(20, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# visualize ndcgs over time\n",
    "avg_random_ndcg = np.mean(random_ndcgs)\n",
    "for idx, lr in enumerate(learning_rates):\n",
    "    ax = axes[idx]\n",
    "    for train_size in train_sizes:\n",
    "        model_ndcgs = model_training_data[f\"{lr}_{train_size}\"][0]\n",
    "        num_posts = model_training_data[f\"{lr}_{train_size}\"][2]\n",
    "        ax.plot(num_posts, model_ndcgs, label=f'Train Size {train_size}')\n",
    "\n",
    "    ax.axhline(y=avg_random_ndcg, color='red', linestyle='--', label='Average Random NDCG')\n",
    "    ax.set_title(f'Model NDCGs by Number of Posts Sampled\\nLearning Rate={lr}', fontsize=14)\n",
    "    ax.set_xlabel('Number of Posts Used', fontsize=12)\n",
    "    ax.set_ylabel('NDCG', fontsize=12)\n",
    "    ax.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_ndcgs_by_posts.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IB6srHH9AJ2E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IB6srHH9AJ2E",
    "outputId": "c8a73754-96d3-4b37-d79d-e49928cda9e5"
   },
   "outputs": [],
   "source": [
    "# load best model to make predictions\n",
    "agent = pairwise_model.RankingAgent(tensor_dims, learning_rate = 0.001, train_size = 15, pretrained_model=best_model)\n",
    "\n",
    "# simulate offline batch processing with data stream\n",
    "ranked_lists = []\n",
    "for _ in tqdm(range(100)):\n",
    "    random_indices = random.sample(X_val, 50)\n",
    "    post_embeddings = telegram_tensors[random_indices]\n",
    "    ranked_indices = agent.rank_posts(post_embeddings)\n",
    "    ranked_post_indices = [random_indices[idx] for idx in ranked_indices]\n",
    "    ranked_lists.append(ranked_post_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HLT5vmuaEWop",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLT5vmuaEWop",
    "outputId": "2b820fd4-91b5-4cd3-d9eb-e017f55e6a51"
   },
   "outputs": [],
   "source": [
    "# generate binary ranked lists with cutoffs\n",
    "cutoffs = [i*5 for i in range(11)]\n",
    "model_recalls = []\n",
    "model_precisions = []\n",
    "model_f1s = []\n",
    "for cutoff in cutoffs:\n",
    "    model_preds = []\n",
    "    true_labels = []\n",
    "    for ranked_list in ranked_lists:\n",
    "        for idx, post_idx in enumerate(ranked_list):\n",
    "            if idx < cutoff:\n",
    "                model_preds.append(1)\n",
    "            else:\n",
    "                model_preds.append(0)\n",
    "            true_label = 1 if telegram_df['reward'][post_idx] > 0 else 0\n",
    "            true_labels.append(true_label)\n",
    "    # collect precision, recall, and f1 from each ranked list\n",
    "    model_recalls.append(recall_score(true_labels, model_preds))\n",
    "    model_precisions.append(precision_score(true_labels, model_preds))\n",
    "    model_f1s.append(f1_score(true_labels, model_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brhfLWmGK2j-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "brhfLWmGK2j-",
    "outputId": "74e36a8e-bb7a-4a5a-d0a5-d8490987d970"
   },
   "outputs": [],
   "source": [
    "#visualize precision-recall curve\n",
    "plt.scatter(model_recalls, model_precisions, label='Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VWrf4FnhY7jd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "VWrf4FnhY7jd",
    "outputId": "ecf24b3c-15a1-4eb8-8de8-ba226b5abce1"
   },
   "outputs": [],
   "source": [
    "#visualizae f1 score at each cutoff\n",
    "plt.plot(cutoffs, model_f1s)\n",
    "plt.xticks([i*5 for i in range(11)])\n",
    "for x in [i * 5 for i in range(11)]:\n",
    "    plt.axvline(x=x, color='black', linestyle='--')\n",
    "plt.xlabel('Cutoff Index')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 score by Index Cutoff')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
